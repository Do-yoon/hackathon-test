# -*- coding: utf-8 -*-
"""추천 알고리즘.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17VBFn7z_h7mo2W0UrgNzvlfyjfo0i1NY
"""

import pandas as pd

# Load the CSV files
keyword_extraction_df = pd.read_csv('/content/keyword_extraction_with_contentid.csv')
combined_detail_df = pd.read_csv('/content/combined_detailfile.csv')

# Merge the two dataframes on 'contentid'
merged_df = pd.merge(keyword_extraction_df, combined_detail_df[['contentid', 'areacode', 'sigungucode']], on='contentid', how='inner')
merged_df = merged_df.iloc[:, :50]

merged_df.head()

import numpy as np
import random

# Merge the two dataframes on 'contentid'
merged_df = pd.merge(keyword_extraction_df, combined_detail_df[['contentid', 'areacode', 'sigungucode']], on='contentid', how='inner')

# Function to scale data using Z-score standardization
def z_score_standardize(values):
    mean_val = np.mean(values)
    std_val = np.std(values)
    if std_val == 0:
        return [0] * len(values)
    return [(x - mean_val) / std_val for x in values]

# Function to recommend items based on scaled scores
def recommend_items_with_z_score_standardized_scores(content_id, df, click_data, top_n=5, random_n=3):
    # Retrieve the labels, scores, and keywords for the given content_id
    target_item = df[df['contentid'] == content_id].iloc[0]
    target_labels = eval(target_item['labels'])
    target_scores = eval(target_item['scores'])
    target_keywords = set(target_item['keywords'].split(', '))

    # Sort click data by recency (assuming it's already sorted by time, but if not, sort by recency here)
    sorted_click_data = list(click_data.items())  # Click data is assumed to be sorted by recency by default

    # Apply weights to clicks based on recency (latest clicks have more weight)
    weighted_click_data = {}
    for index, (content_id, click_count) in enumerate(sorted_click_data):
        weight = 4 - (3 * (index / (len(sorted_click_data) - 1))) if len(sorted_click_data) > 1 else 4
        weighted_click_data[content_id] = click_count * weight

    # Z-score standardize weighted click data
    click_counts = np.array(list(weighted_click_data.values()))
    standardized_click_data = dict(zip(weighted_click_data.keys(), z_score_standardize(click_counts)))

    # Initialize a list to store recommendations with scores
    recommendations = []
    seen_content_ids = set(weighted_click_data.keys())  # Include already clicked content in the seen set

    # Z-score standardize areacode and sigungucode by assigning numerical values
    area_codes = pd.factorize(df['areacode'])[0]
    sigungu_codes = pd.factorize(df['sigungucode'])[0]
    df['areacode_standardized'] = z_score_standardize(area_codes)
    df['sigungucode_standardized'] = z_score_standardize(sigungu_codes)
    df['score_standardized'] = z_score_standardize(df['scores'].apply(eval).apply(np.mean))

    for idx, row in df.iterrows():
        if row['contentid'] == content_id:
            continue

        # Skip if this content ID is already in the seen set
        if row['contentid'] in seen_content_ids:
            continue

        # Compare labels
        current_labels = eval(row['labels'])
        current_scores = eval(row['scores'])
        label_score = sum(min(target_scores[target_labels.index(label)], current_scores[current_labels.index(label)])
                          for label in set(target_labels) & set(current_labels))

        # Compare keywords
        current_keywords = set(row['keywords'].split(', '))
        keyword_score = len(target_keywords & current_keywords)

        # Get standardized scores for area code, sigungu code, and cosine similarity
        area_standardized = row['areacode_standardized']
        sigungu_standardized = row['sigungucode_standardized']
        score_standardized = row['score_standardized']

        # Get standardized click count for the current item, default to 0 if not found
        standardized_click_score = standardized_click_data.get(row['contentid'], 0)

        # Combine scores
        total_score = (area_standardized + sigungu_standardized + score_standardized +
                       standardized_click_score + label_score + keyword_score)

        # Add content to recommendations if not already seen
        recommendations.append((row['contentid'], total_score))
        seen_content_ids.add(row['contentid'])  # Track seen content to avoid duplicates

    # Sort recommendations based on the total score
    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)

    # Take the top 20 items from the sorted recommendations
    top_20_recommendations = recommendations[:20]

    # Select n items randomly from the top 20 recommendations
    random_recommended_content_ids = random.sample([item[0] for item in top_20_recommendations], min(random_n, len(top_20_recommendations)))

    return random_recommended_content_ids

# Example click data (contentid: click count), now expanded to 10 items
click_data = {
    1105871: 4,
    1722369: 3,
    128344: 2,
    130478: 1,
    2007772: 3,
    134675: 4,
    190234: 2,
    287439: 4,
    348290: 1,
    405673: 3
}

# Example: Get recommendations for a specific content ID including standardized scores
example_content_id = 130346
recommended_ids = recommend_items_with_z_score_standardized_scores(example_content_id, merged_df, click_data, top_n=20, random_n=5)

example_sequence = merged_df[merged_df["contentid"] == example_content_id]["sequence"].iloc[0]
print(f"Recommended content IDs for {example_content_id}: {example_sequence}")

# Iterate over recommended_ids and ensure to handle cases where the dataframe might be empty
for id in recommended_ids:
    content_row = merged_df[merged_df["contentid"] == id]
    if not content_row.empty:
        sequence = content_row["sequence"].iloc[0]
        print(f"{id}: {sequence}")
    else:
        print(f"{id}: No data found in dataframe.")

from sklearn.metrics import precision_score, recall_score, f1_score

def evaluate_recommendations(recommended_ids, actual_ids):
    """
    Evaluate the performance of the recommendation system using Precision, Recall, and F1-Score.

    Parameters:
    - recommended_ids (list): List of recommended content IDs.
    - actual_ids (list): List of actual relevant content IDs.

    Returns:
    - precision (float): Precision of the recommendations.
    - recall (float): Recall of the recommendations.
    - f1 (float): F1-Score of the recommendations.
    """
    # Convert actual_ids to a set for faster lookup
    actual_ids_set = set(actual_ids)

    # Calculate True Positives, False Positives, False Negatives
    true_positives = len([id for id in recommended_ids if id in actual_ids_set])
    false_positives = len(recommended_ids) - true_positives
    false_negatives = len(actual_ids) - true_positives

    # Print intermediate results for debugging
    print(f"True Positives: {true_positives}, False Positives: {false_positives}, False Negatives: {false_negatives}")

    # Precision, Recall, F1-Score calculations
    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return precision, recall, f1

# Example correct answers for each content ID (ground truth)
correct_answers = {
    130346: [128344, 2007772, 134675],  # Example correct content IDs for content ID 130346
    # Add more ground truth data as needed
}

# Example: Get recommendations for a specific content ID including standardized scores
example_content_id = 130346
recommended_ids = recommend_items_with_z_score_standardized_scores(example_content_id, merged_df, click_data, top_n=20, random_n=5)

# Debugging: Check if the recommended_ids and correct answers are as expected
print(f"Recommended IDs: {recommended_ids}")
print(f"Correct Answers for Content ID {example_content_id}: {correct_answers[example_content_id]}")

# Evaluate the recommendations
precision, recall, f1 = evaluate_recommendations(recommended_ids, correct_answers[example_content_id])
print(f"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}")